{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"R","language":"R","name":"ir"},"language_info":{"codemirror_mode":"r","file_extension":".r","mimetype":"text/x-r-source","name":"R","pygments_lexer":"r","version":"3.3.1"},"colab":{"name":"Copy of Ejercicio 5 - NLP - Sentiment Analysis","provenance":[{"file_id":"1FxPz750HwH66WD48K7TpRxB3Jdr4GfQ0","timestamp":1601425594054},{"file_id":"16ac6OD7qXXu1Ei2mTp75UBpXtH45DTde","timestamp":1601424152273},{"file_id":"1E2XYRI-6ROObU-6XQzdNJncXBDd7gKoF","timestamp":1573424379932},{"file_id":"1mmJI1FwwBWxTHj_LEGrSIqyJOldgtRNH","timestamp":1572889538921},{"file_id":"1Vq7NINygiwn1RWhTZW2ldomMrWn4i2Cz","timestamp":1571011771513},{"file_id":"1_rsZnC8xnqbGPn8Z8NK0Fs2l-E8NIIMo","timestamp":1570406262095},{"file_id":"1xcSQB0-YEbAZZb4NkQGQt8K0GLcMoeDX","timestamp":1569956773317},{"file_id":"1kqAqDykFDJOPZjQcL9z-EOl2mwG4g4Xy","timestamp":1569836298351},{"file_id":"1nWFDoTmZPjhtpU8M2N_fDwTFtTN2Hy-h","timestamp":1569268538225},{"file_id":"https://github.com/IRkernel/IRkernel/blob/master/example-notebooks/Demo.ipynb","timestamp":1568906751276}],"collapsed_sections":[],"toc_visible":true}},"cells":[{"cell_type":"markdown","metadata":{"id":"BhFF63rsMfbI"},"source":["# Ejercicio 5 - Análisis de sentimientos en texto no-estructurado (NLP)\n","\n","La idea es realizar un simple análisis de sentimiento desde comentarios en medios sociales, por medio de un modelo de clasificación supervisada, que entrega dos posibles valores desde el texto: es un comentario POSITIVO o es NEGATIVO. En este caso no se consideran los neutros. Si algún comentario podría ser definido como neutro por un humano, para este ejemplo fue asociado a positivo o negativo.\n","\n","**IMPORTANTE**: Instrucciones\n","\n","Todos los alumnos, ya sea en grupo, o individualmente (si no tienen compañeros) deben contestar las preguntas que se indicarán, en un email que se deberá enviar al terminar el ejercicio, **incluyendo, en cada respuesta, un pantallazo del resultado y un comentario intepretativo de esos resultados**.\n","\n","El formato del contenido del email es el siguiente, considerando que se pide contestar todo dentro del cuerpo del email o en un PDF adjunto como alternativa (No enviar PPT, ni Word):\n","\n","To: rsandova@ing.puc.cl\n","\n","Subject: Ejercicio 5  Sentiment Analysis aaaammdd\n","\n","Resultados de probar las técnicas de normalización.\n","La más influyente en el resultado es ....\n","\n","\n","Resultados de cambiar la tasa de eliminación de términos infrecuentes o esporádicos\n","Se deduce que al eliminar más términos, se produce ....\n",". . .\n","\n","## Contexto: Análisis de Texto de Comentarios en Medios Sociales de diversos países (Chile, Arg, otros)\n","\n","Este conjunto de datos generado en 2016 por R:Solver y compartido parcialmente para este tipo de ejercicios, consiste en un atributo fundamental, el texto del comentario, y una clasificación dentro de dos alternativas: positivo o negativo.\n","\n","El gran objetivo final a resolver con este ejemplo, es lograr predecir el sentimiento, descrito en la variable de clasificación. "]},{"cell_type":"markdown","metadata":{"id":"nbsvny1wYwsT"},"source":["## Complemento 0: Instalar librerías de modelos de clasificación"]},{"cell_type":"code","metadata":{"id":"Yr8D6ajXY2T9","executionInfo":{"status":"ok","timestamp":1601765521870,"user_tz":180,"elapsed":258781,"user":{"displayName":"Nicolas Sammur","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhkRkX3fFO-cDZ_d0u1-h87VTcO1DJbAFOHxVtKRA=s64","userId":"10396473001908422843"}},"outputId":"d83ae73d-d32b-4e60-8506-0fb83f1334fd","colab":{"base_uri":"https://localhost:8080/","height":407}},"source":["install.packages('e1071')\n","install.packages('caret')\n","install.packages('caTools')\n","install.packages('tm')\n","install.packages('SnowballC')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Installing package into ‘/usr/local/lib/R/site-library’\n","(as ‘lib’ is unspecified)\n","\n","Installing package into ‘/usr/local/lib/R/site-library’\n","(as ‘lib’ is unspecified)\n","\n","also installing the dependencies ‘numDeriv’, ‘SQUAREM’, ‘lava’, ‘prodlim’, ‘iterators’, ‘data.table’, ‘gower’, ‘ipred’, ‘timeDate’, ‘foreach’, ‘plyr’, ‘ModelMetrics’, ‘reshape2’, ‘recipes’, ‘pROC’\n","\n","\n","Installing package into ‘/usr/local/lib/R/site-library’\n","(as ‘lib’ is unspecified)\n","\n","also installing the dependency ‘bitops’\n","\n","\n","Installing package into ‘/usr/local/lib/R/site-library’\n","(as ‘lib’ is unspecified)\n","\n","also installing the dependencies ‘NLP’, ‘slam’\n","\n","\n","Installing package into ‘/usr/local/lib/R/site-library’\n","(as ‘lib’ is unspecified)\n","\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"0q3bYb0RM5bx"},"source":["## Complemento 1: Carga de los datos y definición conjuntos entrenamiento y test\n","\n","La siguiente celda de código carga los datos desde la URL de origen y luego muestra un encabezado con las primeras filas del dataset, para demostrar la disponibilidad de los datos. En esta ocasión, no se espera ni pretende modificar la proporción de datos de entrenamiento vs. test.\n"]},{"cell_type":"code","metadata":{"id":"yIIKPnj-IRE8"},"source":["# Se declara la URL de dónde obtener los datos\n","theUrlMain <- \"http://RAlize.RSolver.com/RAlize/data/small_sample2019clean.csv\"\n","\n","# Se declaran los nombres de las columnas\n","columnas <- c(\"texto\",\"sentimiento\")\n","\n","# Se cargan datos principales a una estructura (commentsdataset), asignando nombres de atributos a las columnas\n","commentsdataset <- read.csv(file = theUrlMain, header = FALSE, sep = \";\", col.names=columnas, skipNul = TRUE)\n","\n","head(commentsdataset)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VGOO7LFAPDL5"},"source":["# Ejercicio: Entender el efecto de cada técnica de normalización de texto\n","\n","Las técnicas de procesamiento de texto, cuando tienen que realizar \"intrepretaciones\" del texto leído, deben buscar la simplificación del texto para poder trabajar sobre palabras equivalentes. Esto puede considerar evitar la diferencia de mayúscula/minúsculas, evitar palabras comunes, usar la raíz de múltiples términos, entre otros.\n","\n","A continuación se aplican algunas de estas diferentes técnicas, mostrando el efecto.\n","\n","**Pregunta central del ejercicio**: ¿cuál de todas estas técnicas es la que logra el mayor efecto positivo en los modelos de análisis de sentimiento de la siguiente sección?\n","\n","Se les pide eliminar (comentar la línea de código respectivo) cada instrucción de normalización y comparar cómo afecta en el accuracy de los modelos más abajo, finalmente determinando cuál es la que tiene mayor efecto.\n"]},{"cell_type":"code","metadata":{"id":"w-RkhmupJGPI"},"source":["library(tm)\n","library(SnowballC)\n","\n","# Transforma la columna \"Texto\" del dataset en un formato vectorial (palabras separadas)\n","corpus <- Corpus(VectorSource(commentsdataset$texto))\n","length(corpus)\n","\n","# Se muestra un ejemplo aleatorio dentro del corpus\n","random_index <- floor(runif(1, min=0, max=length(corpus)))\n","content(corpus[[random_index]])\n","\n","################################\n","# NORMALIZACIÓN DEL TEXTO\n","# EJERCICIO: probar eliminando (comentando) una por una estas acciones\n","# para ver cuál tiene mayor efecto en la calidad del modelo de análisis\n","################################\n","# Se pasan todas las palabras a minúsculas\n","corpus <- tm_map(corpus, tolower)\n","# Se eliminan todos los signos de puntuación\n","corpus <- tm_map(corpus, removePunctuation)\n","# Se eliminan las stop words (palabras comunes, irrelevantes)\n","corpus <- tm_map(corpus, removeWords, c(stopwords(\"spanish\")))\n","# Se lleva cada palabra a su raíz (stemming)\n","corpus <- tm_map(corpus, stemDocument)\n","\n","# Se muestra el mismo ejemplo aleatorio, pero en texto normalizado\n","content(corpus[[random_index]])\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9m6AjrGNtf3x"},"source":["## Construcción de un Vocabulario\n","\n","Los clasificadores pueden recibir un X de entrada de una dimensión fija - idealmente numérica. Por lo tanto los X actuales, que son textos de largo variable, no sirven. La siguiente porción de código construye una matriz de términos del documento (en este caso, el documento es el corpus de texto, con todos los comentarios analizados).\n","\n","A continuación se busca reducir la dimensionalidad del problema (el tamaño del vocabulario) al reconocer cuáles son los términos más relevantes. Esto se hace con FindFreqTerms y un umbral (100 ocurrencias). Mientras mayor es el número, mayor cantidad de términos ocasionales o esporádicos se eliminan. En otras palabras, mientras mayor es el número, mayor es la exigencia para un término de ser considerado valioso.\n","\n","**Ejercicio Complementario**: probar el cambio de cuántos términos esporádicos eliminar (originalmente: 0.995) y ver el efecto que tiene en la calidad del modelo de análisis. Se recomienda moverse en el rango 0.9 a 0.999.\n"]},{"cell_type":"code","metadata":{"id":"_3uvXCD-MdZr"},"source":["#######################################################\n","# Indexación de términos: creación de un Vocabulario\n","#######################################################\n","matriz <- DocumentTermMatrix(corpus)\n","matriz\n","\n","# Se reconocen los términos mas frecuentes con un minimo de 100 veces\n","findFreqTerms(matriz, lowfreq = 100)\n","\n","# Entonces, se eliminan las palabras menos relevantes (sparse terms: términos esporádicos)\n","sparse <- removeSparseTerms(matriz, 0.992)\n","sparse\n","\n","# Re-formatea como un DataFrame\n","bbdd <- as.data.frame(as.matrix(sparse))\n","\n","# Se agrega la columna del Sentimiento\n","colnames(bbdd) = make.names(colnames(bbdd))\n","bbdd$sentimiento <- commentsdataset$sentimiento\n","\n","bbdd$sentimiento <- as.factor(bbdd$sentimiento)\n","\n","str(bbdd$sentimiento)\n","\n","colnames(bbdd)\n","colnames(Test)\n","colnames(Train)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"D1j2-rNWMcnt"},"source":["# Prepara a entrenar, creando dos conjuntos: de entrenamiento y de test\n","library(caTools)\n","set.seed(1)\n","split <- sample.split(bbdd$sentimiento, SplitRatio = 0.6)\n","Train = subset(bbdd, split==TRUE) \n","Test  = subset(bbdd, split==FALSE)\n","\n","dim(Train)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"82LcskQOnNmH"},"source":["## Implementación de modelos de clasificación de referencia\n","\n","Habiendo definido y establecido los conjuntos de entrenamiento y de test, a continuación se ejecutan unos pocos modelos de clasificación: Decision Tree y Naive Bayes. Cada uno obtiene su resultado, mostrando sus precisiones en general.\n"]},{"cell_type":"code","metadata":{"id":"KOpqb-QInkff"},"source":["library(e1071) \n","library(rpart)\n","library(caret)\n","\n","# Aquí va la transformación del texto variable a un vocabulario \n","\n","# Decision Tree\n","tree.model <- rpart(sentimiento ~ ., data=Train, method=\"class\", minbucket=10)\n","tree.predict <- predict(tree.model, Test, type = \"class\")\n","print(\"Resultados Árbol de Decisión\")\n","confusionMatrix(tree.predict, Test$sentimiento) \n","\n","# Naive Bayes\n","NB_model <- naiveBayes(sentimiento ~ ., data=Train)\n","NB_predict <- predict(NB_model, Test)\n","print(\"Resultados Naive Bayes\")\n","confusionMatrix(NB_predict, Test$sentimiento) "],"execution_count":null,"outputs":[]}]}